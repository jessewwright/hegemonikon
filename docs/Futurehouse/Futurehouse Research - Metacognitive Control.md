# Task
Generate a literature review report on computational models of meta-cognitive control and decision conflict resolution.

# Response
Our model, NES, includes a Recursive Adjudication Agent (RAA) triggered by decision stalemate or high conflict. Current implementations involve rule-based adjustments like temporarily boosting urgency or increasing decision thresholds. We need to better understand the range and quantitative implementation of such meta-control mechanisms in existing cognitive architectures.
Please review literature addressing:
Conflict Monitoring & Triggers: Computational models specifying how conflict (e.g., between competing accumulators, or between automatic vs. controlled responses) is detected (often linked to ACC function).
Control Adjustments: Specific, computationally implemented mechanisms by which detected conflict leads to adjustments in decision parameters. Focus on quantitative examples of:
Dynamic threshold adjustments (magnitude, time course, link to STN/theta activity).
Modulation of drift rates or input weighting (e.g., attentional gain control).
Shifts between control strategies (e.g., model-free vs. model-based RL arbitration).
Urgency signal modulation.
Recursion/Reflection: Models involving iterative re-evaluation or bounded recursive processing during difficult decisions.
Neurocomputational Links: Models explicitly linking conflict signals (e.g., simulated ACC output) to specific parameter adjustments in decision or reinforcement learning models.
The goal is to identify diverse, computationally specified mechanisms for resolving conflict/stalemate that could inform more sophisticated implementations of the NES RAA module.

Below is a comprehensive review of computational models of meta‐cognitive control and decision conflict resolution, with a focus on (a) conflict monitoring and trigger detection, (b) control adjustments implemented via dynamic parameter modifications (including dynamic threshold and drift rate modulation, urgency signals, and arbitration between control strategies), (c) recursive or iterative re‐evaluation processes, and (d) neurocomputational links integrating biologically plausible signal propagation mechanisms. This review aims to inform advanced architectures such as the proposed Recursive Adjudication Agent (RAA) in NES.

Introduction  
Recent research has increasingly focused on understanding how the brain detects conflict during decision-making and then uses that information to adjust control parameters in an adaptive manner. Models of meta‐cognitive control integrate mechanisms from reinforcement learning, accumulator dynamics, and oscillatory neural activity to explain how decisions are modified in face of conflicting or ambiguous signals. In particular, computational approaches have been developed that simulate different aspects of conflict detection and subsequent control adjustments in neural and cognitive architectures. Such models form an essential foundation for systems like NES that incorporate a Recursive Adjudication Agent (RAA), which is triggered by decision stalemate or high conflict and currently relies on rule‐based adjustments, such as temporary boosts in urgency or raising decision thresholds. A key goal of this review is to review the range and quantitative implementations of meta‐control mechanisms that have been reported, with an emphasis on aspects including conflict monitoring triggers, dynamic threshold adjustment (with quantification in magnitude and time course, and links to subthalamic nucleus and theta oscillatory activity), drift rate modulation through attentional gain, shifts between control strategies (e.g., arbitration between model‐free versus model‐based reinforcement learning), urgency signal modulation, and recursive re‐evaluation.

Conflict Monitoring and Triggers  
A central element in many computational approaches is the detection of conflict as a precursor to control adjustments. One influential strand of work links conflict detection to activity in the anterior cingulate cortex (ACC). Several models assume that conflict is computed as a mismatch between competing response representations or as the accumulation of evidence in disparate neural accumulators. For example, accumulator models conceptualize conflict in terms of competing accumulators that dynamically integrate noisy evidence until one response threshold is reached; when the evidence levels are too close to each other, the resulting conflict triggers adaptation in the decision process (cohen2014aneuralmicrocircuit pages 1-2). This framework has been extended by models that simulate the role of the ACC as a conflict monitor, where the ACC produces a signal that reflects either the weighted difference between conflicting response tendencies or the degree of violation in expected outcomes (vassena2017computationalmodelsof pages 1-2). These models capture several empirical phenomena observed with neuroimaging and electrophysiology; for instance, increased midfrontal theta power is often associated with conflict detection when automatic responses compete with task‐relevant responses (cohen2014aneuralmicrocircuit pages 2-3).

In addition, meta‐cognitive models often attribute a conflict‐triggering role to prediction errors generated during decision making. For example, reinforcement-learning-based models posit that deviations between expected and observed outcomes (reward or state prediction errors) serve as triggers for control adjustments (silvetti2014fromconflictmanagement pages 1-2). In these models, the ACC is conceptualized as a “critic” that tracks such prediction errors, and an increase in prediction error magnitude is taken to represent a signal of conflict or uncertainty in the decision process (vassena2017computationalmodelsof pages 7-7). Neuroimaging studies have reported that increased ACC activation during tasks with high response conflict correlates with behavioral measures of slowing or increased decision caution, supporting the view that the ACC is positioned at the crossroads of conflict detection and control adjustment (li2017conflictdetectionand pages 27-32).

Other studies have emphasized that conflict can be detected not only by monitoring errors or prediction mismatches but also by measuring discrepancies between automatic and controlled responses. For example, models integrating reinforcement learning with accumulator models have linked the dynamic modulation of response thresholds to the intensity of conflict signals detected by the ACC (holroyd2021thebestlaid pages 2-3). In such frameworks, if the “distance” between competing accumulators is too small or the conflict signal persists over time, a trigger is generated to engage more deliberative, controlled processing, which may then be implemented via adjustments to decision parameters. Thus, conflict monitoring mechanisms in these computational models are sensitive to both instantaneous error signals and accumulated conflict over time (cohen2014aneuralmicrocircuit pages 8-9).

Control Adjustments  
Once conflict is detected, the system must respond by adjusting control parameters to resolve the decision conflict. A variety of mechanisms have been proposed and quantitatively implemented in computational models.

Dynamic Threshold Adjustments  
One common mechanism in conflict resolution models is the adjustment of the decision threshold. In accumulator models (e.g., drift-diffusion models), increasing the threshold requires more evidence to be accumulated before a response is initiated, serving to delay the decision and reduce the likelihood of errors when conflict is detected. Empirical findings indicate that the magnitude and time course of threshold adjustments correlate with neural signals in the ACC and subthalamic nucleus (STN). For example, studies have shown that when conflict is detected, increased theta-band activity over medial frontal cortex—thought to be generated in ACC—correlates with increased thresholds, as implemented by dynamic adjustments in the drift-diffusion model (frank2015fmriandeeg pages 8-9). Additional work proposes that the STN acts as a modulatory hub that regulates motor output by transiently increasing response thresholds in high-conflict situations. Computational implementations have quantified how the dynamic threshold adjustment scales with conflict intensity (e.g., an increased threshold value by a certain fixed magnitude or a multiplicative factor), suggesting that this parameter modulates gradually over a short time window following conflict detection (holroyd2021thebestlaid pages 8-10).

Modulation of Drift Rates or Input Weighting  
Another strategy for adjusting cognitive processing in the face of conflict is by modulating the rate at which evidence is accumulated. In decision-making models, the drift rate reflects the quality or strength of sensory or value information. Models have been developed in which conflict detection leads to a reallocation of attentional resources, effectively weighting the inputs that contribute to the drift. For instance, computational models that incorporate attentional gain control propose that when a conflict is detected, attentional resources are directed more strongly toward task-relevant inputs, thereby increasing the drift rate for the appropriate response while dampening contributions from distracting or biasing inputs (vassena2017computationalmodelsof pages 4-5). This mechanism is implemented quantitatively by altering the drift rate parameter based on conflict signal intensity, which can be calibrated to match observed reaction time distributions in tasks requiring high control (cohen2014aneuralmicrocircuit pages 8-9).

Moreover, re-weighting of the input may also occur in multi-alternative choice models, where the relative weight assigned to each competing option is adjusted in a context-dependent manner. Such models have been used to explain how shifts in attentional priority, reflected by changes in drift rates, can resolve conflict between automatic tendencies and goal-relevant responses. Empirical support for these mechanisms is provided by neuroimaging studies linking frontoparietal activations to flexible adjustments of sensory gain during tasks involving conflict (li2017conflictdetectionand pages 27-32).

Shifts Between Control Strategies  
Meta-cognitive control often involves arbitration between qualitatively distinct strategies. A common distinction in the literature is between model-free and model-based reinforcement learning (RL) systems. In many computational models, these two systems represent habit-based versus goal-directed control policies, respectively, and the arbitration between them is driven by the reliability of their predictions. Computational models that combine these systems typically incorporate an arbitration mechanism that monitors prediction errors from both systems and dynamically shifts the balance of control (lee2014neuralcomputationsunderlying pages 1-2, kim2018taskcomplexityinteracts pages 14-17). In these models, a weighted “reliability signal” computed from errors such as state prediction errors for the model-based system and reward prediction errors for the model-free system determines which system’s control policy is dominant at any given time. When conflict arises, for example when the habitual response is in opposition to a goal-relevant alternative, the system may transiently favor a model-based strategy by increasing its weight. These models are implemented mathematically by adjusting the softmax temperature parameter or the weighting factors in the value function, thereby biasing decision-making toward the more reliable control strategy. The inferior lateral prefrontal cortex has been implicated as a neural substrate mediating this arbitration, with fMRI data supporting the idea that this region encodes reliability signals for both learning systems (lee2014neuralcomputationsunderlying pages 7-8, kim2018taskcomplexityinteracts pages 28-33).

Urgency Signal Modulation  
Another mechanism for adapting control under conflict is the modulation of urgency signals. Urgency models describe how the accumulation process becomes increasingly “urgent” over time, thereby effectively reducing response thresholds as deadlines approach. Some computational models propose that under conditions of high conflict, urgency signals may be temporarily boosted to force faster resolutions or, conversely, be suppressed to allow more evidence accumulation. Although less common than threshold or drift rate adjustments, models incorporating urgency signals propose that a time-dependent function modulates the level of urgency. This modulation can be expressed quantitatively as a multiplicative factor applied to the drift rate or a time-varying term that directly lowers the threshold as time progresses. Empirical work has linked changes in urgency signals to neural markers in the prefrontal cortex and subthalamic nucleus (STN), consistent with theories that argue for an adaptive “braking” mechanism when conflict is detected (frank2015fmriandeeg pages 8-9).

Control Adjustments via Recursion/Reflection  
Beyond immediate parameter adjustments, some computational models incorporate recursive or iterative re-evaluation of the decision process during difficult or high-conflict situations. These models propose that when a decision reaches a stalemate or high conflict state, the system re-invokes its evaluation process to reconsider prior evidence and update its internal estimates. For example, recursive neural network models simulate bounded recursive processing, where the output of an initial decision stage is fed back into the network for further refinement. Such architectures can capture complex dynamics where the system oscillates between alternative policy evaluations until one option surpasses the control threshold (holroyd2021thebestlaid pages 6-8). Although these models are less common, they provide a promising framework for implementing a Recursive Adjudication Agent (RAA) that iteratively recalculates decision parameters under stalemate conditions.

Neurocomputational Links  
The integration of conflict detection and control adjustment in computational models is supported by a growing body of neuroimaging and electrophysiological evidence. Many models explicitly link conflict signals to modulations in decision parameters via neural substrates such as the ACC, STN, and lateral prefrontal cortex. For instance, models featuring dynamic threshold adjustments consistently associate increases in the decision threshold with ACC activity and midline theta oscillations. Empirical evidence from combined fMRI–EEG studies demonstrates that prefrontal regions increase activity and synchronize in the theta band during high-conflict trials, and these dynamics are effectively captured by integrating an urgency or threshold-modulation term in computational models (cohen2014aneuralmicrocircuit pages 8-9, holroyd2021thebestlaid pages 3-4). 

Other neurocomputational models propose that the ACC signals conflict via prediction error mechanisms that serve as proxies for uncertainty. These prediction error signals then feed forward to modulate control parameters in downstream decision-making processes, effectively serving as a “teaching signal” for re-weighting inputs. For example, models based on the Reward Value Prediction Model (RVPM) and the Predicted Response Outcome (PRO) model simulate ACC output that quantitatively influences drift rate and threshold adjustments by encoding the magnitude of prediction errors for conflicting responses (silvetti2014fromconflictmanagement pages 9-10, vassena2017computationalmodelsof pages 9-9).

Moreover, some models integrate arbitration between control strategies with neurocomputational findings such as those linking inferior prefrontal cortex activity with reliability signals from both model-based and model-free systems (lee2014neuralcomputationsunderlying pages 7-8, kim2018taskcomplexityinteracts pages 28-33). This neural arbitration process can be conceptualized as comparing competing predictions via Bayesian estimation, where conflict is resolved by allocating control to the strategy with the most reliable prediction. Such frameworks have been quantitatively implemented in behavioral computational models that simulate choice behavior under conflict (lee2014neuralcomputationsunderlying pages 1-2, kim2019taskcomplexityinteracts pages 8-9).

Taken together, the neurocomputational links demonstrate that meta-cognitive control is not a monolithic process but emerges from the interaction of multiple neural circuits. Controlled adjustments in decision parameters—ranging from dynamic threshold modulation to drift rate adjustments and shifts in control strategy—are all quantitatively linked to conflict signals that are observable in the brain. These signals, especially as measured from regions like the ACC and lateral prefrontal cortex, provide the necessary feedback for adaptive decision-making and are well captured by current computational models.

Implications for Advanced Architectures  
For systems such as NES that include a Recursive Adjudication Agent (RAA), the reviewed literature provides several promising directions. First, the ability to simulate conflict detection via accumulator models or prediction error mechanisms suggests that a similar trigger can be computationally defined in NES. A quantitative conflict signal could be derived from comparing multiple accumulators representing alternative decisions, or from monitoring deviations between expected and actual outcomes. This signal could then drive recursive re-evaluation processes that adjust decision parameters. 

Second, quantitative implementations of dynamic threshold adjustments offer a clear computational mechanism for resolving decision conflict. For instance, a conflict-triggered rule whereby the decision threshold is increased by a factor proportional to the detected conflict signal over a defined temporal window has been implemented in several models (frank2015fmriandeeg pages 8-9, holroyd2021thebestlaid pages 8-10). Such a mechanism would allow the RAA module to temporarily “buy time” by requiring more accumulated evidence before committing to a decision.

Third, modulation of drift rates via input weighting or attentional gain control is another mechanism that could support the RAA. By dynamically adjusting the weight assigned to different inputs (or evidence streams) in response to conflict detection, the system can prioritize task-relevant information and attenuate interference from automatic, competing responses (vassena2017computationalmodelsof pages 4-5, cohen2014aneuralmicrocircuit pages 8-9). This mechanism provides a quantitative method by which urgency signals can also be modulated—for example, by linking the rate of evidence accumulation to an urgency signal that is itself adjustable on the basis of conflict intensity.

Fourth, the arbitration between model-free and model-based control strategies is well documented in the literature. Models that integrate these dual systems—where arbitration is based on relative prediction error reliabilities—offer a clear computational framework for shifting control strategies during high-conflict or stalemate conditions (lee2014neuralcomputationsunderlying pages 7-8, kim2018taskcomplexityinteracts pages 14-17). In practice, NES could adopt a similar strategy by calculating a reliability measure for each control policy and reallocating computational resources based on a quantitative threshold. Such reallocation could be implemented as a dynamic switch or a graded blending of policies, depending on the degree of conflict detected.

Fifth, recursive processing models highlight the benefit of iterative re-evaluation when conflict remains unresolved after an initial control adjustment. While many existing models implement a one-shot adjustment (e.g., a transient threshold boost), recent developments advocate for a bounded recursive process, whereby the decision is updated iteratively until the conflict signal falls below a critical value (holroyd2021thebestlaid pages 6-8). This iterative adjudication could be incorporated into the RAA, allowing the system to engage in multiple rounds of parameter updates (e.g., re-boosting urgency or further increasing the decision threshold) until a clear resolution is reached.

Lastly, neurocomputational studies make an explicit link between simulated neural signals and quantitative control adjustments. For example, midline theta oscillations measured in the ACC have been quantitatively correlated with the magnitude of dynamic threshold adjustments observed in decision-making tasks. This kind of neurophysiologically grounded modeling is essential for designing systems that not only perform well on abstract computational tasks, but also emulate biological decision-making processes. By integrating neural-inspired signals—such as simulated ACC output corresponding to a conflict signal—with algorithmic mechanisms for threshold, drift rate, or strategy modulation, future implementations of the NES RAA module could achieve more sophisticated and adaptive meta-cognitive control (cohen2014aneuralmicrocircuit pages 2-3, holroyd2021thebestlaid pages 3-4).

Conclusion  
A diverse array of computational models has been developed to address meta-cognitive control and decision conflict resolution. Conflict monitoring is typically implemented via accumulator or prediction error models that emulate ACC function, while control adjustments are executed by dynamically modulating decision thresholds, drift rates, and urgency signals. Quantitative examples include models that compute increases in threshold magnitude proportional to conflict signals and those that adjust drift rates based on attentional gain control. Furthermore, arbitration between control strategies—such as shifting between model-free and model-based reinforcement learning—has been formalized using reliability measures derived from prediction errors. Recursive or iterative frameworks offer an additional layer of adaptability when initial conflict resolution is insufficient. Neurocomputational links observed in neuroimaging and electrophysiological studies have provided a critical bridge between abstract computational mechanisms and biologically plausible implementations.

For advanced cognitive architectures like NES, which incorporate a Recursive Adjudication Agent (RAA), these diverse computational mechanisms offer a rich toolkit. By incorporating conflict detection based on accumulator dynamics or prediction error measures, followed by quantitative control adjustments (such as dynamic threshold or drift rate modulation), and by enabling iterative re-evaluation under high conflict, future implementations can achieve greater flexibility and robustness in decision-making. Integration of arbitration mechanisms that dynamically balance model-free and model-based policies further enhances the adaptive capacity of such systems. Ultimately, the convergence of theoretical modeling, quantitative simulation, and neural data provides a path forward for developing sophisticated meta‐cognitive control modules that mirror the complex interplay observed in biological systems (frank2015fmriandeeg pages 8-9, li2017conflictdetectionand pages 27-32, holroyd2021thebestlaid pages 2-3).

This review has drawn on multiple studies that contribute to our understanding of the quantitative and neurocomputational mechanisms underlying conflict monitoring and control adjustments. By evaluating these models, one can design more elaborate meta-control architectures that better mimic the adaptive, recursive, and context-sensitive decision processes observed in humans and animals. Future work may benefit from further integration of neural oscillatory dynamics, recursive feedback loops, and real-time arbitration between control policies to arrive at an even more comprehensive computational framework for meta-cognitive control and decision conflict resolution (vassena2017computationalmodelsof pages 1-2, cohen2014aneuralmicrocircuit pages 8-9, kim2018taskcomplexityinteracts pages 28-33).

## References

1. (frank2015fmriandeeg pages 8-9): Michael J. Frank, Chris Gagne, Erika Nyhus, Sean Masters, Thomas V. Wiecki, James F. Cavanagh, and David Badre. Fmri and eeg predictors of dynamic decision parameters during human reinforcement learning. The Journal of Neuroscience, 35:485-494, Jan 2015. URL: https://doi.org/10.1523/jneurosci.2036-14.2015, doi:10.1523/jneurosci.2036-14.2015. This article has 282 citations.

2. (li2017conflictdetectionand pages 27-32): Qi Li, Guochun Yang, Zhenghan Li, Yanyan Qi, Michael W. Cole, and Xun Liu. Conflict detection and resolution rely on a combination of common and distinct cognitive control networks. Neuroscience &amp; Biobehavioral Reviews, 83:123-131, Dec 2017. URL: https://doi.org/10.1016/j.neubiorev.2017.09.032, doi:10.1016/j.neubiorev.2017.09.032. This article has 77 citations.

3. (silvetti2014fromconflictmanagement pages 1-2): Massimo Silvetti, William Alexander, Tom Verguts, and Joshua W. Brown. From conflict management to reward-based decision making: actors and critics in primate medial frontal cortex. Neuroscience &amp; Biobehavioral Reviews, 46:44-57, Oct 2014. URL: https://doi.org/10.1016/j.neubiorev.2013.11.003, doi:10.1016/j.neubiorev.2013.11.003. This article has 140 citations.

4. (vassena2017computationalmodelsof pages 7-7): Eliana Vassena, Clay B. Holroyd, and William H. Alexander. Computational models of anterior cingulate cortex: at the crossroads between prediction and effort. Frontiers in Neuroscience, Jun 2017. URL: https://doi.org/10.3389/fnins.2017.00316, doi:10.3389/fnins.2017.00316. This article has 147 citations and is from a peer-reviewed journal.

5. (cohen2014aneuralmicrocircuit pages 1-2): Michael X. Cohen. A neural microcircuit for cognitive conflict detection and signaling. Trends in Neurosciences, 37:480-490, Sep 2014. URL: https://doi.org/10.1016/j.tins.2014.06.004, doi:10.1016/j.tins.2014.06.004. This article has 432 citations and is from a highest quality peer-reviewed journal.

6. (cohen2014aneuralmicrocircuit pages 2-3): Michael X. Cohen. A neural microcircuit for cognitive conflict detection and signaling. Trends in Neurosciences, 37:480-490, Sep 2014. URL: https://doi.org/10.1016/j.tins.2014.06.004, doi:10.1016/j.tins.2014.06.004. This article has 432 citations and is from a highest quality peer-reviewed journal.

7. (cohen2014aneuralmicrocircuit pages 8-9): Michael X. Cohen. A neural microcircuit for cognitive conflict detection and signaling. Trends in Neurosciences, 37:480-490, Sep 2014. URL: https://doi.org/10.1016/j.tins.2014.06.004, doi:10.1016/j.tins.2014.06.004. This article has 432 citations and is from a highest quality peer-reviewed journal.

8. (holroyd2021thebestlaid pages 2-3): Clay B. Holroyd and Tom Verguts. The best laid plans: computational principles of anterior cingulate cortex. Trends in Cognitive Sciences, 25:316-329, Apr 2021. URL: https://doi.org/10.1016/j.tics.2021.01.008, doi:10.1016/j.tics.2021.01.008. This article has 74 citations and is from a highest quality peer-reviewed journal.

9. (holroyd2021thebestlaid pages 3-4): Clay B. Holroyd and Tom Verguts. The best laid plans: computational principles of anterior cingulate cortex. Trends in Cognitive Sciences, 25:316-329, Apr 2021. URL: https://doi.org/10.1016/j.tics.2021.01.008, doi:10.1016/j.tics.2021.01.008. This article has 74 citations and is from a highest quality peer-reviewed journal.

10. (holroyd2021thebestlaid pages 8-10): Clay B. Holroyd and Tom Verguts. The best laid plans: computational principles of anterior cingulate cortex. Trends in Cognitive Sciences, 25:316-329, Apr 2021. URL: https://doi.org/10.1016/j.tics.2021.01.008, doi:10.1016/j.tics.2021.01.008. This article has 74 citations and is from a highest quality peer-reviewed journal.

11. (kim2018taskcomplexityinteracts pages 28-33): Dongjae Kim, Geon Yeong Park, John P. O’Doherty, and Sang Wan Lee. Task complexity interacts with state-space uncertainty in the arbitration process between model-based and model-free reinforcement-learning at both behavioral and neural levels. bioRxiv, Aug 2018. URL: https://doi.org/10.1101/393983, doi:10.1101/393983. This article has 7 citations.

12. (lee2014neuralcomputationsunderlying pages 7-8): Sang Wan Lee, Shinsuke Shimojo, and John P. O’Doherty. Neural computations underlying arbitration between model-based and model-free learning. Neuron, 81:687-699, Feb 2014. URL: https://doi.org/10.1016/j.neuron.2013.11.028, doi:10.1016/j.neuron.2013.11.028. This article has 722 citations and is from a highest quality peer-reviewed journal.

13. (silvetti2014fromconflictmanagement pages 9-10): Massimo Silvetti, William Alexander, Tom Verguts, and Joshua W. Brown. From conflict management to reward-based decision making: actors and critics in primate medial frontal cortex. Neuroscience &amp; Biobehavioral Reviews, 46:44-57, Oct 2014. URL: https://doi.org/10.1016/j.neubiorev.2013.11.003, doi:10.1016/j.neubiorev.2013.11.003. This article has 140 citations.

14. (vassena2017computationalmodelsof pages 1-2): Eliana Vassena, Clay B. Holroyd, and William H. Alexander. Computational models of anterior cingulate cortex: at the crossroads between prediction and effort. Frontiers in Neuroscience, Jun 2017. URL: https://doi.org/10.3389/fnins.2017.00316, doi:10.3389/fnins.2017.00316. This article has 147 citations and is from a peer-reviewed journal.

15. (vassena2017computationalmodelsof pages 4-5): Eliana Vassena, Clay B. Holroyd, and William H. Alexander. Computational models of anterior cingulate cortex: at the crossroads between prediction and effort. Frontiers in Neuroscience, Jun 2017. URL: https://doi.org/10.3389/fnins.2017.00316, doi:10.3389/fnins.2017.00316. This article has 147 citations and is from a peer-reviewed journal.

16. (vassena2017computationalmodelsof pages 9-9): Eliana Vassena, Clay B. Holroyd, and William H. Alexander. Computational models of anterior cingulate cortex: at the crossroads between prediction and effort. Frontiers in Neuroscience, Jun 2017. URL: https://doi.org/10.3389/fnins.2017.00316, doi:10.3389/fnins.2017.00316. This article has 147 citations and is from a peer-reviewed journal.

17. (holroyd2021thebestlaid pages 6-8): Clay B. Holroyd and Tom Verguts. The best laid plans: computational principles of anterior cingulate cortex. Trends in Cognitive Sciences, 25:316-329, Apr 2021. URL: https://doi.org/10.1016/j.tics.2021.01.008, doi:10.1016/j.tics.2021.01.008. This article has 74 citations and is from a highest quality peer-reviewed journal.

18. (kim2018taskcomplexityinteracts pages 14-17): Dongjae Kim, Geon Yeong Park, John P. O’Doherty, and Sang Wan Lee. Task complexity interacts with state-space uncertainty in the arbitration process between model-based and model-free reinforcement-learning at both behavioral and neural levels. bioRxiv, Aug 2018. URL: https://doi.org/10.1101/393983, doi:10.1101/393983. This article has 7 citations.

19. (kim2019taskcomplexityinteracts pages 8-9): Dongjae Kim, Geon Yeong Park, John P. O′Doherty, and Sang Wan Lee. Task complexity interacts with state-space uncertainty in the arbitration between model-based and model-free learning. Nature Communications, Dec 2019. URL: https://doi.org/10.1038/s41467-019-13632-1, doi:10.1038/s41467-019-13632-1. This article has 62 citations and is from a highest quality peer-reviewed journal.

20. (lee2014neuralcomputationsunderlying pages 1-2): Sang Wan Lee, Shinsuke Shimojo, and John P. O’Doherty. Neural computations underlying arbitration between model-based and model-free learning. Neuron, 81:687-699, Feb 2014. URL: https://doi.org/10.1016/j.neuron.2013.11.028, doi:10.1016/j.neuron.2013.11.028. This article has 722 citations and is from a highest quality peer-reviewed journal.
