# Task
Generate a literature review report on computational cognitive models of learning and representing abstract rules, social norms, or values.

# Response
Our model, NES, includes a Norm Repository and a Learning Engine that updates internal norm weights based on prediction error (m_j(k) = m_j(k-1) + η * (outcome(k) - tanh(m_j(k-1)))). We need to ground this mechanism and the representation of norms more deeply in existing research.
Please review literature addressing:
Norm/Rule Representation: How are abstract rules, social norms, deontic constraints (obligations/prohibitions), or multi-attribute values computationally represented in cognitive models (e.g., symbolic structures, connectionist weights, Bayesian parameters, utility functions)?
Learning Mechanisms: How are these representations acquired and updated from experience? Focus on:
Models differentiating normative/rule prediction errors from standard reward prediction errors.
Bayesian approaches to learning structure, rules, or latent causes (e.g., HGF, structure learning models).
Reinforcement learning approaches applied to learning policies or values in rule-based or social contexts (e.g., actor-critic, meta-RL for control states).
Models of instruction-based learning or observational/social learning of norms.
Integration with Decision-Making: How do learned norm/value representations influence downstream decision processes (e.g., modulating DDM parameters, constraining RL policies, guiding planning)?
The goal is to understand the state-of-the-art in computationally modeling the acquisition, representation, and updating of normative knowledge to inform the NES Learning Engine and Norm Repository design.

This literature review examines computational cognitive models that represent and learn abstract rules, social norms, deontic constraints, and values, with a focus on integrating these representations into decision‐making. In our discussion we ground the Norm Evaluation System (NES)—which incorporates a Norm Repository and a Learning Engine updating internal norm weights via a prediction error‐based rule (m_j(k) = m_j(k–1) + η · [outcome(k) – tanh(m_j(k–1))])—in existing research on norm representation, learning mechanisms, and their integration with decision processes.

## 1. Norm/Rule Representation

A central issue in modeling normative knowledge is the representation of abstract rules and social norms. Early computational models often employed symbolic structures such as explicit rule‐based and deontic logic formalisms to capture obligations, permissions, and prohibitions. For instance, standard deontic logic (SDL) and its extensions have been applied to represent normative constraints in cognitive architectures, with approaches focusing on encoding “ought‐to‐do” statements and dyadic obligations directly into formal logical systems; these symbolic representations typically involve modal operators and logical conditions that define normative outcomes (ciabattoni2308deonticparadoxesin pages 10-12). Similar symbolic approaches have been evident in normative multi‐agent frameworks, where architectures such as BOID (Belief-Obligation-Intention-Desire) and normative extensions of the BDI (Belief-Desire-Intention) framework provide cognitive agents with explicit obligation components integrated into planning and action selection processes (beheshti2015cognitivesociallearners pages 1-2).

In addition to classical deontic logic representations, researchers have emphasized multi-attribute representations of social values and culturally sanctioned metrics. For example, computational frameworks have been proposed that describe culture‐sanctioned social metrics (CSSMs) which quantify abstract social values such as dignity, politeness, and generosity; these models harness numerical metrics to represent norms in a manner similar to utility functions, enabling agents to compute and predict norm compliance and violations in dynamic social contexts (boloni2018towardsacomputational pages 2-3, boloni2018towardsacomputational pages 15-15).

Beyond purely symbolic representations, connectionist models use weighted connections in neural networks to implicitly codify interrelated normative concepts. These models represent abstract rules as distributed activation patterns across nodes in parallel constraint satisfaction networks, in which the constraints imposed by social norms and values interact to influence overall activation patterns that can guide behavior (read2014connectionistmodelsof pages 10-12, read2014connectionistmodelsof pages 70-72). In such connectionist systems, abstract norm representations are not stored as discrete rules but are emergent from a network’s connection weights, with localist representations sometimes used when interpretability is paramount (read2014connectionistmodelsof pages 12-15).

A third perspective integrates Bayesian inference into normative representation, with parameters viewed as probabilistic beliefs over latent normative causes. In these models, uncertainty about the applicability or strength of a norm is captured through Bayesian parameters, enabling agents to update norm beliefs based on evidence and prior expectations—a viewpoint that offers a bridge between symbolic representations and statistical decision theory (endress2013bayesianlearningand pages 1-2, hawkins2019theemergenceof pages 7-8). Thus, computational models can represent norms through a spectrum: symbolic logics define explicit, interpretable normative rules; connectionist systems encode these rules implicitly via distributed weights; and Bayesian models use probabilistic parameters to capture learning and uncertainty regarding norms.

## 2. Learning Mechanisms for Norm and Rule Acquisition

Learning abstract rules and social norms from experience is a multifaceted process that has been modeled using various approaches. One class of models focuses on error-driven updates similar to reinforcement learning. In our NES model, the norm weight update rule is reminiscent of a prediction error mechanism where outcome discrepancies—between actual experiences and activated normative predictions represented through a non-linear function (tanh)—adjust internal norm weights. This mirrors standard actor-critic and error-correction schemes that update policy-relevant signals; however, a subset of models differentiates normative prediction errors from standard reward prediction errors (yilmaz2017computationalmodelsof pages 1-5). For instance, in normative decision frameworks, agents use specific error signals to update normative expectations separate from instrumental rewards, thus allowing for the differential learning of ethical rules or obligations versus reward contingencies (yilmaz2017computationalmodelsof pages 5-9).

Reinforcement learning (RL) approaches have been well studied in domains such as social decision-making, where agents learn policies based on both extrinsic rewards and internalized norm-values. In these cases, actor-critic models or meta-RL architectures have been adapted so that norm predictors influence the policy network, effectively constraining the space of permitted actions (bulling2016normbasedmechanismdesign pages 2-3). In parallel, bottom-up learning models have been applied, where agents learn normative values through social interactions, mimicry, and observational learning; the Cognitive Social Learners (CSL) architecture, for example, integrates both belief-desire-intention reasoning and game-theoretic elements to capture norm emergence from interaction (beheshti2015cognitivesociallearners pages 2-3, beheshti2015cognitivesociallearners pages 6-7).

Bayesian approaches offer an alternative perspective here by positing that agents use structure learning to infer latent normative rules, much like models used in concept and grammar acquisition. In these models, the agent maintains probabilistic beliefs over a space of possible normative “hypotheses” and updates these beliefs in light of consistent evidence, akin to hierarchical Gaussian filter (HGF) models where normative structures are modulated by prediction errors weighted by uncertainty (endress2013bayesianlearningand pages 1-2). Although not all models explicitly segregate normative prediction errors from reward prediction errors, the integration of Bayesian structure learning principles allows an agent to infer latent causes underlying normative behavior, which in turn offers a principled framework for updating norm weights in our NES Learning Engine.

Instruction-based learning and observational social learning have also been modeled to address how norms are transmitted within groups. Several computational frameworks have demonstrated that agents can quickly acquire normative rules through direct instruction or by observing the actions of more experienced or paid attention peers. These models often combine symbolic rule representations with learning algorithms that modify rule weights based on the teacher’s input or the frequency of observed norm compliance, thereby refining the internal norm repository (yilmaz2017computationalmodelsof pages 9-14, beheshti2015cognitivesociallearners pages 7-7). Such hybrid approaches blend symbolic encoding with reinforcement and Bayesian updates, creating an adaptive norm repository that evolves with the agent’s experience.

The specific update in our NES model, using a hyperbolic tangent transformation within the prediction error term, is conceptually similar to error-correction learning seen in connectionist models, where non-linearity helps bound the norm activations and ensures gradual convergence (read2014connectionistmodelsof pages 10-12). This design reflects an acknowledgment that norm weights may saturate, and only incremental adjustments are necessary once a norm is strongly established or rejected—a phenomenon widely observed in both neural network training and normative behavior updating.

## 3. Integration of Norm Representations with Decision-Making

Once abstract normative rules and social values are represented and learned, their integration with the overall decision-making process is critical. In many cognitive architectures, learned normative information is used to constrain the action space and modulate decision variables during planning and execution. For example, symbolic normative representations in deontic logic can serve as constraints within planning algorithms such that any plan violating a prescribed norm is discarded or penalized. This approach has been adopted in studies on norm-based mechanism design where institutional norms modify the underlying game structure or the available transitions in multi-agent environments (bulling2016normbasedmechanismdesign pages 30-31).

Normative influences on decision-making have also been modeled using connectionist and hybrid approaches. In constraint satisfaction networks designed for ethical decision-making, nodes representing normative beliefs interact with nodes representing rewards, goals, and perceptual evidence. The dynamic evolution of activation across such networks, as seen in coherence-driven reflective equilibrium models, effectively balances normative constraints (e.g., obligations or prohibitions) with empirical evidence and personal goals so that the final decision reflects a state of maximal coherence (yilmaz2017computationalmodelsof pages 14-18, yilmaz2017computationalmodelsof pages 18-23). In these models, a convergence of activation serves as a decision threshold, analogous to the drift-diffusion model (DDM) in which neural integrators accumulate evidence until a threshold is crossed; here, norm-based activations can modulate the drift rate or the threshold, thereby shifting the decision outcome toward norm-compliant actions.

Reinforcement learning frameworks provide another route by incorporating learned normative value estimates as part of the overall utility function. In such setups, the total reward function is augmented with an additional normative term that either boosts or penalizes actions depending on their degree of norm compliance. This hybrid utility function allows standard RL policies to be sensitive to abstract normative features, guiding exploration and exploitation toward socially acceptable behaviors (bulling2016normbasedmechanismdesign pages 31-32, yilmaz2017computationalmodelsof pages 29-33). Such integration is crucial in domains where normative conformity is as important as extrinsic rewards, for example in ethical decision-making systems or social robotics.

Moreover, Bayesian decision models have been proposed in which normative beliefs, updated through probabilistic inference, influence posterior action distributions. These models permit agents to weigh the cost of norm violations against the prospective benefits of an action, within a formal probabilistic framework that can be seamlessly integrated into sequential decision-making processes (hawkins2019theemergenceof pages 7-8). In these settings, the norm representation not only informs the agent about what is socially acceptable but also provides a measurable parameter that can bias choices in uncertain environments—a concept that resonates with the idea of “soft” constraints in decision theory.

Instruction-based models have further highlighted that explicit normative guidance can rapidly orient decision-making in novel contexts. Agents that receive an initial set of instructions or observe a normative exemplar can quickly integrate this information, sometimes through a one-shot learning mechanism, into their decision-making circuits. This enables rapid adjustment of decision policies even when the underlying normative structure is complex or subject to change, providing a computational justification for rapidly adaptive norm repositories like that in NES (yilmaz2017computationalmodelsof pages 23-29).

## 4. Synthesis and Implications for NES

The state-of-the-art in computational modeling of abstract rule, norm, and value representation indicates that effective systems combine multiple representational paradigms and learning mechanisms. Symbolic models employ explicit logical formalisms such as deontic logic and normative BDI architectures that capture the structure of social norms and obligations; these models offer clarity and interpretability but can be brittle when norms evolve or when confronted with ambiguous real-world situations (ciabattoni2308deonticparadoxesin pages 10-12, beheshti2015cognitivesociallearners pages 1-2). In contrast, connectionist models, with their distributed representations and error-driven updating, provide a robust mechanism for adapting norm weights over time, as alignment of activation patterns across networks mirrors learning in natural cognitive systems (read2014connectionistmodelsof pages 10-12). Bayesian models further enrich norm-learning by offering principled methods for integrating uncertainty and prior belief structures, thereby enabling the inference of latent normative structures from noisy observational data (endress2013bayesianlearningand pages 1-2, hawkins2019theemergenceof pages 7-8).

Our NES Learning Engine, with its update rule based on prediction error modulated by a tanh non-linearity, can be interpreted as residing at the intersection of these modeling streams. The use of a bounded non-linear update aligns with principles from connectionist error-correction learning while offering a clear computational analogue to normative prediction errors distinct from traditional reward prediction errors (yilmaz2017computationalmodelsof pages 1-5, read2014connectionistmodelsof pages 10-12). Furthermore, the norm repository’s role in storing representations that are either explicitly coded (as in symbolic systems) or implicitly distributed (as in connectionist systems) suggests that a hybrid approach may be ideal. By allowing norm weights to serve as Bayesian parameters that are updated iteratively based on experience, the NES system stands to benefit from the strengths of each modeling paradigm and to resolve some shortcomings that arise when one approach is used in isolation.

The integration of learned norm representations with decision-making in NES mirrors mechanisms observed in both normative mechanism design and reflective equilibrium models. Norm-based modulations have been shown to influence planning and action selection, thereby ensuring that normative considerations are not peripheral but are central to the decision process (bulling2016normbasedmechanismdesign pages 30-31, yilmaz2017computationalmodelsof pages 14-18). For instance, by biasing the decision threshold or the utility evaluations within an RL or Bayesian decision-making module, the system can effectively prevent or discourage norm-violating behavior without entirely precluding the possibility of exploration (yilmaz2017computationalmodelsof pages 23-29, bulling2016normbasedmechanismdesign pages 31-32). This modulation is particularly important in domains such as ethical robotics or socially interactive agents, where adhering to deontic constraints is paramount for safe and acceptable behavior.

Moreover, the literature indicates that a successful integration of norm learning and decision-making requires not only an adaptive learning mechanism but also an architecture that allows feedback from decision outcomes to inform future norm weight updates. In many contemporary cognitive models, prediction error signals derived from social norm violations (or compliance) serve as a teaching signal that refines both the normative representation and the decision policy concurrently (yilmaz2017computationalmodelsof pages 5-9, beheshti2015cognitivesociallearners pages 2-3). This form of joint learning is essential when normative expectations and environmental contingencies are dynamically intertwined, ensuring that the agent’s internal models remain calibrated to the current social context.

## 5. Future Directions and Open Challenges

Despite significant progress, several challenges remain in fully capturing the dynamics of norm learning and integration within cognitive architectures. One open question is how to effectively distinguish normative prediction errors from conventional reward prediction errors in environments where both external rewards and social sanctions co-occur. Some recent work suggests that dual-learning systems may be necessary, in which separate prediction errors are computed for normative outcomes and instrumental rewards before being combined to influence action selection (yilmaz2017computationalmodelsof pages 1-5, bulling2016normbasedmechanismdesign pages 2-3).

Another research direction involves refining Bayesian structure learning methods to better disambiguate latent normative causes from redundant or irrelevant information. Here, the challenge is to design inference algorithms that can cope with complex social interactions and dynamic cultural influences, allowing agents to adapt their normative models over long time scales while remaining responsive to short-term shifts in social context (endress2013bayesianlearningand pages 1-2, hawkins2019theemergenceof pages 7-8). Such approaches may involve integrating hierarchical Bayesian frameworks with reinforcement learning models so that higher-level normative abstractions are learned alongside lower-level policy representations.

Advances in connectionist models of social reasoning also point to opportunities for improved integration of symbolic and sub-symbolic approaches. Recent recent work on parallel constraint satisfaction and connectionist coherence models demonstrates that neural networks can embody abstract reasoning about social norms, offering a promising avenue for developing hybrid systems that combine the interpretability of symbolic models with the flexibility of connectionist learning (read2014connectionistmodelsof pages 10-12, read2014connectionistmodelsof pages 70-72). An ideal system would allow for explicit symbolic norm representations that are continuously refined by gradient-based learning mechanisms, providing an account that is both neurally plausible and computationally efficient.

Finally, it remains important to empirically validate these models in scenarios that closely mimic real-world social interactions. Experimental paradigms using agent-based simulations and iterated learning experiments have provided some preliminary evidence that computational models can capture the emergence and evolution of social norms under controlled conditions (hawkins2019theemergenceof pages 5-7, hawkins2019theemergenceof pages 7-8). As these models become more refined, integrating them with realistic environmental simulations and human-agent interaction studies will be essential for testing the assumptions and performance of systems like NES.

## 6. Conclusion

In summary, the computational cognitive modeling of abstract rules, social norms, and values encompasses a diverse array of methods. Symbolic approaches grounded in deontic logic provide explicit normative representations, while connectionist models capture the distributed and dynamic nature of norm learning through weighted activation and error-driven updates. Bayesian frameworks further enhance these models by incorporating uncertainty and latent structure learning, and reinforcement learning techniques—particularly those that segregate normative prediction errors from standard reward signals—offer practical learning mechanisms that update norm weights through experience.

Our NES model, with its prediction error–based learning rule and norm repository architecture, is well grounded in this literature. By drawing on insights from symbolic normative reasoning (ciabattoni2308deonticparadoxesin pages 10-12, beheshti2015cognitivesociallearners pages 1-2), connectionist learning dynamics (read2014connectionistmodelsof pages 10-12, read2014connectionistmodelsof pages 70-72), and Bayesian inference processes (endress2013bayesianlearningand pages 1-2, hawkins2019theemergenceof pages 7-8), our approach offers a theoretically robust and empirically informed pathway for integrating norm representations with decision-making. Moreover, by examining models that include distinct normative prediction error signals (yilmaz2017computationalmodelsof pages 1-5, yilmaz2017computationalmodelsof pages 5-9) and that integrate normative values into planning and control (bulling2016normbasedmechanismdesign pages 30-31, yilmaz2017computationalmodelsof pages 14-18), we can further refine the NES architecture to ensure that norm updating is both adaptive in complex social contexts and effective in guiding downstream decisions.

Future work should focus on empirical validation through agent-based simulations and human interaction experiments, the integration of hierarchical Bayesian methods for norm inference, and the development of hybrid architectures that blend symbolic interpretability with connectionist flexibility. Such endeavors will not only improve our understanding of norm learning in cognitive systems but will also enable the design of more socially attuned artificial agents across diverse application domains.

(yiłmaz2017computationalmodelsof pages 1-5, ciabattoni2308deonticparadoxesin pages 10-12, boloni2018towardsacomputational pages 2-3)

## References

1. (boloni2018towardsacomputational pages 2-3): Ladislau Bölöni, Taranjeet Singh Bhatia, Saad Ahmad Khan, Jonathan Streater, and Stephen M. Fiore. Towards a computational model of social norms. PLOS ONE, 13:e0195331, Apr 2018. URL: https://doi.org/10.1371/journal.pone.0195331, doi:10.1371/journal.pone.0195331. This article has 15 citations and is from a peer-reviewed journal.

2. (ciabattoni2308deonticparadoxesin pages 10-12): A Ciabattoni and T Eiter. Deontic paradoxes in asp with weak constraints. ArXiv, 2308. URL: https://doi.org/10.48550/arxiv.2308.15870, doi:10.48550/arxiv.2308.15870.

3. (yilmaz2017computationalmodelsof pages 1-5): Levent Yilmaz, Ana Franco-Watkins, and Timothy S. Kroecker. Computational models of ethical decision-making: a coherence-driven reflective equilibrium model. Cognitive Systems Research, 46:61-74, Dec 2017. URL: https://doi.org/10.1016/j.cogsys.2017.02.005, doi:10.1016/j.cogsys.2017.02.005. This article has 26 citations and is from a peer-reviewed journal.

4. (yilmaz2017computationalmodelsof pages 5-9): Levent Yilmaz, Ana Franco-Watkins, and Timothy S. Kroecker. Computational models of ethical decision-making: a coherence-driven reflective equilibrium model. Cognitive Systems Research, 46:61-74, Dec 2017. URL: https://doi.org/10.1016/j.cogsys.2017.02.005, doi:10.1016/j.cogsys.2017.02.005. This article has 26 citations and is from a peer-reviewed journal.

5. (yilmaz2017computationalmodelsof pages 9-14): Levent Yilmaz, Ana Franco-Watkins, and Timothy S. Kroecker. Computational models of ethical decision-making: a coherence-driven reflective equilibrium model. Cognitive Systems Research, 46:61-74, Dec 2017. URL: https://doi.org/10.1016/j.cogsys.2017.02.005, doi:10.1016/j.cogsys.2017.02.005. This article has 26 citations and is from a peer-reviewed journal.

6. (beheshti2015cognitivesociallearners pages 1-2): Rahmatollah Beheshti, Awrad Mohammed Ali, and Gita Sukthankar. Cognitive social learners: an architecture for modeling normative behavior. Proceedings of the AAAI Conference on Artificial Intelligence, 29:2017-2023, Feb 2015. URL: https://doi.org/10.1609/aaai.v29i1.9441, doi:10.1609/aaai.v29i1.9441. This article has 20 citations and is from a domain leading peer-reviewed journal.

7. (beheshti2015cognitivesociallearners pages 2-3): Rahmatollah Beheshti, Awrad Mohammed Ali, and Gita Sukthankar. Cognitive social learners: an architecture for modeling normative behavior. Proceedings of the AAAI Conference on Artificial Intelligence, 29:2017-2023, Feb 2015. URL: https://doi.org/10.1609/aaai.v29i1.9441, doi:10.1609/aaai.v29i1.9441. This article has 20 citations and is from a domain leading peer-reviewed journal.

8. (beheshti2015cognitivesociallearners pages 6-7): Rahmatollah Beheshti, Awrad Mohammed Ali, and Gita Sukthankar. Cognitive social learners: an architecture for modeling normative behavior. Proceedings of the AAAI Conference on Artificial Intelligence, 29:2017-2023, Feb 2015. URL: https://doi.org/10.1609/aaai.v29i1.9441, doi:10.1609/aaai.v29i1.9441. This article has 20 citations and is from a domain leading peer-reviewed journal.

9. (beheshti2015cognitivesociallearners pages 7-7): Rahmatollah Beheshti, Awrad Mohammed Ali, and Gita Sukthankar. Cognitive social learners: an architecture for modeling normative behavior. Proceedings of the AAAI Conference on Artificial Intelligence, 29:2017-2023, Feb 2015. URL: https://doi.org/10.1609/aaai.v29i1.9441, doi:10.1609/aaai.v29i1.9441. This article has 20 citations and is from a domain leading peer-reviewed journal.

10. (boloni2018towardsacomputational pages 15-15): Ladislau Bölöni, Taranjeet Singh Bhatia, Saad Ahmad Khan, Jonathan Streater, and Stephen M. Fiore. Towards a computational model of social norms. PLOS ONE, 13:e0195331, Apr 2018. URL: https://doi.org/10.1371/journal.pone.0195331, doi:10.1371/journal.pone.0195331. This article has 15 citations and is from a peer-reviewed journal.

11. (read2014connectionistmodelsof pages 10-12): SJ Read and LC Miller. Connectionist models of social reasoning and social behavior. Unknown journal, Jan 2014. URL: https://doi.org/10.4324/9781315785257, doi:10.4324/9781315785257. This article has 251 citations.

12. (read2014connectionistmodelsof pages 12-15): SJ Read and LC Miller. Connectionist models of social reasoning and social behavior. Unknown journal, Jan 2014. URL: https://doi.org/10.4324/9781315785257, doi:10.4324/9781315785257. This article has 251 citations.

13. (read2014connectionistmodelsof pages 70-72): SJ Read and LC Miller. Connectionist models of social reasoning and social behavior. Unknown journal, Jan 2014. URL: https://doi.org/10.4324/9781315785257, doi:10.4324/9781315785257. This article has 251 citations.

14. (yilmaz2017computationalmodelsof pages 14-18): Levent Yilmaz, Ana Franco-Watkins, and Timothy S. Kroecker. Computational models of ethical decision-making: a coherence-driven reflective equilibrium model. Cognitive Systems Research, 46:61-74, Dec 2017. URL: https://doi.org/10.1016/j.cogsys.2017.02.005, doi:10.1016/j.cogsys.2017.02.005. This article has 26 citations and is from a peer-reviewed journal.

15. (yilmaz2017computationalmodelsof pages 18-23): Levent Yilmaz, Ana Franco-Watkins, and Timothy S. Kroecker. Computational models of ethical decision-making: a coherence-driven reflective equilibrium model. Cognitive Systems Research, 46:61-74, Dec 2017. URL: https://doi.org/10.1016/j.cogsys.2017.02.005, doi:10.1016/j.cogsys.2017.02.005. This article has 26 citations and is from a peer-reviewed journal.

16. (yilmaz2017computationalmodelsof pages 23-29): Levent Yilmaz, Ana Franco-Watkins, and Timothy S. Kroecker. Computational models of ethical decision-making: a coherence-driven reflective equilibrium model. Cognitive Systems Research, 46:61-74, Dec 2017. URL: https://doi.org/10.1016/j.cogsys.2017.02.005, doi:10.1016/j.cogsys.2017.02.005. This article has 26 citations and is from a peer-reviewed journal.

17. (yilmaz2017computationalmodelsof pages 29-33): Levent Yilmaz, Ana Franco-Watkins, and Timothy S. Kroecker. Computational models of ethical decision-making: a coherence-driven reflective equilibrium model. Cognitive Systems Research, 46:61-74, Dec 2017. URL: https://doi.org/10.1016/j.cogsys.2017.02.005, doi:10.1016/j.cogsys.2017.02.005. This article has 26 citations and is from a peer-reviewed journal.

18. (bulling2016normbasedmechanismdesign pages 2-3): Nils Bulling and Mehdi Dastani. Norm-based mechanism design. Artificial Intelligence, 239:97-142, Oct 2016. URL: https://doi.org/10.1016/j.artint.2016.07.001, doi:10.1016/j.artint.2016.07.001. This article has 45 citations and is from a highest quality peer-reviewed journal.

19. (bulling2016normbasedmechanismdesign pages 30-31): Nils Bulling and Mehdi Dastani. Norm-based mechanism design. Artificial Intelligence, 239:97-142, Oct 2016. URL: https://doi.org/10.1016/j.artint.2016.07.001, doi:10.1016/j.artint.2016.07.001. This article has 45 citations and is from a highest quality peer-reviewed journal.

20. (bulling2016normbasedmechanismdesign pages 31-32): Nils Bulling and Mehdi Dastani. Norm-based mechanism design. Artificial Intelligence, 239:97-142, Oct 2016. URL: https://doi.org/10.1016/j.artint.2016.07.001, doi:10.1016/j.artint.2016.07.001. This article has 45 citations and is from a highest quality peer-reviewed journal.

21. (endress2013bayesianlearningand pages 1-2): Ansgar D. Endress. Bayesian learning and the psychology of rule induction. Cognition, 127:159-176, May 2013. URL: https://doi.org/10.1016/j.cognition.2012.11.014, doi:10.1016/j.cognition.2012.11.014. This article has 37 citations and is from a highest quality peer-reviewed journal.

22. (hawkins2019theemergenceof pages 5-7): Robert X.D. Hawkins, Noah D. Goodman, and Robert L. Goldstone. The emergence of social norms and conventions. Trends in Cognitive Sciences, 23:158-169, Feb 2019. URL: https://doi.org/10.1016/j.tics.2018.11.003, doi:10.1016/j.tics.2018.11.003. This article has 155 citations and is from a highest quality peer-reviewed journal.

23. (hawkins2019theemergenceof pages 7-8): Robert X.D. Hawkins, Noah D. Goodman, and Robert L. Goldstone. The emergence of social norms and conventions. Trends in Cognitive Sciences, 23:158-169, Feb 2019. URL: https://doi.org/10.1016/j.tics.2018.11.003, doi:10.1016/j.tics.2018.11.003. This article has 155 citations and is from a highest quality peer-reviewed journal.
